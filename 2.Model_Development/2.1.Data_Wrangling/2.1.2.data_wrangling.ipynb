{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](../../README.md)\n",
    "\n",
    "### Data Wrangling\n",
    "\n",
    "This is a demonstration of data wrangling using [Pandas](https://pandas.pydata.org/) the library for data analysis and manipulation.\n",
    "\n",
    "This Jupyter Notepad demonstrates different processes you can apply to your data to prepare it for feature engineering and model training. For this demonstration we will wrangle the diabetes data set you previewed in the last Jupyter Notebook.\n",
    "\n",
    "> [!Note]\n",
    "> None of these processes are destructive to the source CSV as long as you save the modified data to a new CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Store the data as a local variable\n",
    "\n",
    "The data frame is a Pandas object that structures your tabular data into an appropriate format. It loads the complete data in memory so it is now ready for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"2.1.2.diabeties_sample_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with null values\n",
    "\n",
    "Null values during data analysis can cause runtime errors and unexpected results. It is important to identify null values and deal with them appropriately before training a model.\n",
    "\n",
    "The `isnull().sum()` method call returns the null values in any column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoB       0\n",
       "DoT       0\n",
       "SEX       1\n",
       "BMI       0\n",
       "BP        0\n",
       "TC        0\n",
       "BGU       0\n",
       "FDR       0\n",
       "Target    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have null data there are many ways to deal with the empty/null values. These are the two most common approaches.\n",
    "1. Remove any row with a null value with a `dropna()` method call.\n",
    "2. Replace missing values with another value with a `fillna()` method call. Generally, we use mean value for numerical columns because it may cause minimal changes in your mathematical analysis while maintaining the original size of the data.\n",
    "\n",
    "Students should reflect why this example removes the null 'SEX' but replacing the mean 'Target'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoB       0\n",
       "DoT       0\n",
       "SEX       0\n",
       "BMI       0\n",
       "BP        0\n",
       "TC        0\n",
       "BGU       0\n",
       "FDR       0\n",
       "Target    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Null values\n",
    "data_frame = data_frame.dropna(subset=['SEX'])\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoB       0\n",
       "DoT       0\n",
       "SEX       0\n",
       "BMI       0\n",
       "BP        0\n",
       "TC        0\n",
       "BGU       0\n",
       "FDR       0\n",
       "Target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace Null values with the mean value for the column\n",
    "data_frame['Target'] = data_frame['Target'].fillna(data_frame['Target'].mean())\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Duplicates\n",
    "\n",
    "Duplicate data can have detrimental effects on your machine learning models and outcomes, such as reducing data diversity and representativeness, which can lead to overfitting or biased models.\n",
    "\n",
    "The `duplicated().sum()` method call returns the count of duplicate rows in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `drop_duplicates()` method call can be then stored back onto the data_frame variable removing the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = data_frame.drop_duplicates()\n",
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace data\n",
    "\n",
    "We can run a lambda function on a column to modify its values. For a simple example, letâ€™s convert the Sex to lowercase. To run a function over a complete column, we can use the apply method which iterates over each row and modifies the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    female\n",
       "1    female\n",
       "2      male\n",
       "3      male\n",
       "4      male\n",
       "Name: SEX, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['SEX'] = data_frame['SEX'].apply(lambda x: x.lower())\n",
    "data_frame['SEX'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that there are no data entry errors by the `unique()` method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male', 'girl'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['SEX'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['SEX'] = data_frame['SEX'].apply(lambda gender: 'male' if gender.lower() == 'male' else 'female')\n",
    "data_frame['SEX'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outliers\n",
    "\n",
    "Outliers can skew your analysis on numerical columns, and it is important to remove them. We can use the 25th and 75th quartile on numerical data, to get the inter-quartile range. This allows us to estimate an acceptable range, and we can then filter out any values outside this range. Mathematically, outliers are values occurring outside 1.5 times the interquartile range (IQR) from the first quartile (Q1) or third quartile (Q3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    439.000000\n",
      "mean       0.465684\n",
      "std        0.162238\n",
      "min        0.082353\n",
      "25%        0.341176\n",
      "50%        0.447059\n",
      "75%        0.588235\n",
      "max        0.917647\n",
      "Name: BP, dtype: float64\n",
      "Outliers are a BP above 0.9588235294117647 or below -0.02941176470588236\n",
      "\n",
      "count    439.000000\n",
      "mean      26.361276\n",
      "std        4.428303\n",
      "min       18.000000\n",
      "25%       23.150000\n",
      "50%       25.700000\n",
      "75%       29.250000\n",
      "max       42.200000\n",
      "Name: BMI, dtype: float64\n",
      "Outliers are a BMI above 38.400000000000006 or below 13.999999999999996\n",
      "\n",
      "count    439.000000\n",
      "mean      91.275626\n",
      "std       11.492468\n",
      "min       58.000000\n",
      "25%       83.500000\n",
      "50%       91.000000\n",
      "75%       98.000000\n",
      "max      124.000000\n",
      "Name: BGU, dtype: float64\n",
      "Outliers are a BGU above 119.75 or below 61.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"print('')\\n#get the inter-quartile range on the blood pressure column\\nprint(data_frame['FHRisk'].describe())\\nQ1 = data_frame['FHRisk'].quantile(0.25)\\nQ3 = data_frame['FHRisk'].quantile(0.75)\\nIQR = Q3 - Q1\\nprint(f'Outliers are a FHRisk above {Q3 + IQR * 1.5} or below {Q1 - IQR * 1.5}')\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the inter-quartile range on the blood pressure column\n",
    "print(data_frame['BP'].describe())\n",
    "Q1 = data_frame['BP'].quantile(0.25)\n",
    "Q3 = data_frame['BP'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(f'Outliers are a BP above {Q3 + IQR * 1.5} or below {Q1 - IQR * 1.5}')\n",
    "\n",
    "print('')\n",
    "#get the inter-quartile range on the blood pressure column\n",
    "print(data_frame['BMI'].describe())\n",
    "Q1 = data_frame['BMI'].quantile(0.25)\n",
    "Q3 = data_frame['BMI'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(f'Outliers are a BMI above {Q3 + IQR * 1.5} or below {Q1 - IQR * 1.5}')\n",
    "\n",
    "print('')\n",
    "#get the inter-quartile range on the blood pressure column\n",
    "print(data_frame['BGU'].describe())\n",
    "Q1 = data_frame['BGU'].quantile(0.25)\n",
    "Q3 = data_frame['BGU'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(f'Outliers are a BGU above {Q3 + IQR * 1.5} or below {Q1 - IQR * 1.5}')\n",
    "\n",
    "#no such column apparenty as FHRisk? dont think theres an equivalent either\n",
    "'''print('')\n",
    "#get the inter-quartile range on the blood pressure column\n",
    "print(data_frame['FHRisk'].describe())\n",
    "Q1 = data_frame['FHRisk'].quantile(0.25)\n",
    "Q3 = data_frame['FHRisk'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(f'Outliers are a FHRisk above {Q3 + IQR * 1.5} or below {Q1 - IQR * 1.5}')'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: BP, dtype: float64\n",
      "\n",
      "BMI\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: BMI, dtype: float64\n",
      "\n",
      "BGU\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: BGU, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filter blood pressure within the acceptable range\n",
    "data_frame = data_frame[(data_frame['BP'] >= Q1 - 1.5 * IQR) & (data_frame['BP'] <= Q3 + 1.5 * IQR)]\n",
    "print('BP')\n",
    "print(data_frame['BP'].describe())\n",
    "\n",
    "data_frame = data_frame[(data_frame['BMI'] >= Q1 - 1.5 * IQR) & (data_frame['BMI'] <= Q3 + 1.5 * IQR)]\n",
    "print('\\nBMI')\n",
    "print(data_frame['BMI'].describe())\n",
    "\n",
    "data_frame = data_frame[(data_frame['BGU'] >= Q1 - 1.5 * IQR) & (data_frame['BGU'] <= Q3 + 1.5 * IQR)]\n",
    "print('\\nBGU')\n",
    "print(data_frame['BGU'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling features to a common range\n",
    "\n",
    "Scaling the features makes it easier for machine learning algorithms to find the optimal solution, as the different scales of the features do not influence them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>TC</th>\n",
       "      <th>BGU</th>\n",
       "      <th>FDR</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BMI   BP   TC  BGU  FDR  Target\n",
       "count  0.0  0.0  0.0  0.0  0.0     0.0\n",
       "mean   NaN  NaN  NaN  NaN  NaN     NaN\n",
       "std    NaN  NaN  NaN  NaN  NaN     NaN\n",
       "min    NaN  NaN  NaN  NaN  NaN     NaN\n",
       "25%    NaN  NaN  NaN  NaN  NaN     NaN\n",
       "50%    NaN  NaN  NaN  NaN  NaN     NaN\n",
       "75%    NaN  NaN  NaN  NaN  NaN     NaN\n",
       "max    NaN  NaN  NaN  NaN  NaN     NaN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_feature = 'BP'\n",
    "\n",
    "#the minimum value with space for outliers\n",
    "MIN_BP = 55\n",
    "\n",
    "#the maximum value with space for outliers\n",
    "MAX_BP = 140\n",
    "\n",
    "#scale features\n",
    "data_frame[scale_feature] = [(X - MIN_BP) / (MAX_BP - MIN_BP) for X in data_frame[scale_feature]]\n",
    "\n",
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!important]\n",
    "> You need to save the calculations for each dataset you scale for scaling new values for prediction. Use [2.1.2.data.records.md](2.1.2.data.records.md) to record this information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the wrangled data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('../2.2.Feature_Engineering/2.2.1.wrangled_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
